<%@ page language="java" contentType="text/html; charset=ISO-8859-1"
    pageEncoding="ISO-8859-1"%>
    <%@page import="java.io.BufferedWriter"%>
<%@page import="java.io.File"%>
<%@page import="java.io.FileNotFoundException"%>
<%@page import="java.io.FileOutputStream"%>
<%@page import="java.io.OutputStreamWriter"%>
<%@page import="java.net.SocketTimeoutException"%>
<%@page import="org.jsoup.*"%>
<%@page import="org.jsoup.helper.HttpConnection"%>
<%@page import="org.jsoup.nodes.Document"%>
<%@page import="org.jsoup.nodes.Element"%>
<%@page import="org.jsoup.select.Elements"%>
<%@page import="java.awt.Desktop"%>



<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<title>Demo</title>

<style>#apDiv4 {
	position:absolute;
	width:200px;
	height:115px;
	z-index:2;
	left: 350px;
	top: 69px;
}

#apDiv1 {
	position:absolute;
	width:200px;
	height:115px;
	z-index:1;
	left: 786px;
	top: 42px;
}

body  {
	font-family: "Comic Sans MS";
}



</style>

</head>
<body>
<div class="container" style="background-image:url(BG_capture.JPG); background-repeat:no-repeat;"> 
  <div id="apDiv1"><img src="Logo_Picture.jpg" width="250" height="83.33" alt="Logo" /></div>
  
  <p>
   The use of search engines to locate information has grown steadily based on the needs of users generating a snowball effect,<br>
   where all the information is available in different websites, 
   <br>including information that is not useful. A situation arises where in we find 
   <br>ourselves in a situation that does not allow us to locate appropriate information on the web using 
   <br>multiple
    web portals. 
   <br>Before the Web became the most visible part of the Internet, 
   <br>there were already search engines in place to help people find information on the Net. Programs with names like gopher and Archie kept 
   <br>indexes of files stored on servers connected to the Internet, and dramatically reduced the amount of time required to find programs and documents. 
   In the late 1980s, 
   <br>getting serious value from the Internet meant knowing how to use gopher, Archie, Veronica and the rest.<br>
  There are currently functioning as search sites called metasearch that help review the information that throw the other search engines,
  <br> but searching normally, only responsible for presenting results on screen as a search interface running on multiple search engines.<br>
  Some of the most common difficulties we come across while managing the web are ï‚· To maintain mirror sites for popular Web sites. </p>
<p>1) To test web pages and links for valid syntax and structure.<br>
<p>2) To monitor sites to see when their structure or contents ch1ange. <br>
<p>3) To search for copyright infringements. <br>
<p>4)To build a special-purpose index. For example, one that has some understanding of the content stored in multimedia files on the Web.<br>

A generic solution to the above problems is to build a web crawler that extracts information from the web that is present in an unstructured manner and finally we subject the same to a process of restructuring that simplifies the task of accessing data.<br>

				    	        
</body>
</html>